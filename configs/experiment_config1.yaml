wandb:  
  debug: false
  project: "test"
  experiment_lot: "MyExperiment" 
  


dataset:
  # "squad"/'svamp'/'nq'/"trivia_qa"/'trustful_qa_mc1'/'trustful_qa_mc2'
  name: "squad"
  seed: 42
  answerable_only: True

prompt:
  #few-shot setting
  few-shot: False
  shot_num: 3
  brief_always: True
  use_context: True
  # prompt
  add_tag: True
  prompt_template_path: "/home/yw699/codes/LLM-Hallu/data/prompt_templates/ask_templates/test2.txt"
  

model:
  model_name: "meta-llama/Llama-2-7b-hf"
  stop_sequences: "default"     # None/"default"
  max_new_tokens: 50
  
sample:
  temperature: 1.0
  sample_count: 5
  sampling_method: "simple_sample"    # "simple_sample"/"adv_prompt_sample"/"similar_prompt_sample"/"process_change_sample"
  
  
 
metrics:
  - name: "p_true"
    p_true_num_fewshot: 2
    
  - name: "accuracy"
  - name: "diversity"


p_true:
  compute_p_true: True
  get_training_set_generations: True
  get_training_set_generations_most_likely_only: True
  compute_accuracy_at_all_temps: True
  p_true_hint : False

