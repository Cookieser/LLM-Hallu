_wandb:
    value:
        cli_version: 0.18.6
        m: []
        python_version: 3.11.10
        t:
            "1":
                - 1
                - 11
                - 49
                - 51
                - 55
                - 71
            "2":
                - 1
                - 11
                - 49
                - 51
                - 55
                - 71
            "3":
                - 2
                - 16
                - 23
                - 55
            "4": 3.11.10
            "5": 0.18.6
            "6": 4.46.2
            "8":
                - 1
                - 5
            "12": 0.18.6
            "13": linux-x86_64
dataset:
    value:
        answerable_only: true
        name: squad
        seed: 42
model:
    value:
        max_new_tokens: 50
        model_name: meta-llama/Llama-2-7b-hf
        stop_sequences: default
prompt:
    value:
        add_tag: true
        brief_always: true
        few-shot: false
        prompt_template_path: /home/yw699/codes/LLM-Hallu/data/prompt_templates/ask_templates/test2.txt
        shot_num: 3
        use_context: true
sample:
    value:
        metrics:
            - p_true
            - accuracy
            - diversity
        sample_count: 5
        sampling_method: simple_sample
        temperature: 1
wandb:
    value:
        debug: false
        experiment_lot: MyExperiment
        project: test
