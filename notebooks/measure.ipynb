{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "os.chdir(\"/home/yw699/codes/LLM-Hallu\")\n",
    "sys.path.append(os.path.abspath(\"src\"))\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6,7\"\n",
    "from utils import *\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"configs/experiment_config1.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "    \n",
    "wandb_config = config[\"wandb\"]\n",
    "metrics_config = config[\"metrics\"]\n",
    "experiment_details = {'config': config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Name: ethereal-smoke-21\n",
      "Run Config: {'model': {'model_name': 'meta-llama/Llama-2-7b-hf', 'max_new_tokens': 50, 'stop_sequences': 'default'}, 'wandb': {'debug': False, 'project': 'semantic_uncertainty', 'experiment_lot': 'MyExperiment'}, 'p_true': {'p_true_hint': False, 'compute_p_true': True, 'get_training_set_generations': True, 'compute_accuracy_at_all_temps': True, 'get_training_set_generations_most_likely_only': True}, 'prompt': {'add_tag': True, 'few-shot': False, 'shot_num': 3, 'use_context': True, 'brief_always': True, 'prompt_template_path': '/home/yw699/codes/LLM-Hallu/data/prompt_templates/ask_templates/test2.txt'}, 'sample': {'temperature': 1, 'sample_count': 5, 'sampling_method': 'simple_sample'}, 'dataset': {'name': 'squad', 'seed': 42, 'answerable_only': True}, 'metrics': [{'name': 'p_true', 'p_true_num_fewshot': 2}, {'name': 'accuracy'}, {'name': 'diversity'}], 'p_true_num_fewshot': 2}\n",
      "Run Summary: {'_runtime': 42.354001356, '_step': 0, '_timestamp': 1732048160.6579254, '_wandb': {'runtime': 42}, 'len_p_true': 2}\n",
      "File Name: requirements.txt\n",
      "File Name: wandb-metadata.json\n",
      "File Name: yw699/uncertainty/wandb/run-20241119_152837-k0fk4l54/files/experiment_details.pkl\n",
      "File Name: yw699/uncertainty/wandb/run-20241119_152837-k0fk4l54/files/train_generations.pkl\n",
      "File Name: yw699/uncertainty/wandb/run-20241119_152837-k0fk4l54/files/uncertainty_measures.pkl\n",
      "File Name: yw699/uncertainty/wandb/run-20241119_152837-k0fk4l54/files/validation_generations.pkl\n"
     ]
    }
   ],
   "source": [
    "wandb_id = 'k0fk4l54'\n",
    "if wandb_id == 'YOUR_ID':\n",
    "    raise ValueError('Need to provide wandb_id of demo run!')\n",
    "\n",
    "api = wandb.Api()\n",
    "old_run = api.run(f'semantic_uncertainty/{wandb_id}')\n",
    "\n",
    "print(\"Run Name:\", old_run.name)\n",
    "print(\"Run Config:\", old_run.config)\n",
    "print(\"Run Summary:\", old_run.summary)\n",
    "\n",
    "\n",
    "for file in old_run.files():\n",
    "    print(\"File Name:\", file.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myupuwang2001\u001b[0m (\u001b[33myupuwang2001-duke-university\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./yw699/uncertainty/wandb/run-20241119_203456-3rp0xrrf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yupuwang2001-duke-university/semantic_uncertainty/runs/3rp0xrrf' target=\"_blank\">lucky-butterfly-29</a></strong> to <a href='https://wandb.ai/yupuwang2001-duke-university/semantic_uncertainty' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yupuwang2001-duke-university/semantic_uncertainty' target=\"_blank\">https://wandb.ai/yupuwang2001-duke-university/semantic_uncertainty</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yupuwang2001-duke-university/semantic_uncertainty/runs/3rp0xrrf' target=\"_blank\">https://wandb.ai/yupuwang2001-duke-university/semantic_uncertainty/runs/3rp0xrrf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/yupuwang2001-duke-university/semantic_uncertainty/runs/3rp0xrrf?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fe0f3106f90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = os.environ['USER']\n",
    "slurm_jobid = os.getenv('SLURM_JOB_ID', None)\n",
    "scratch_dir = os.getenv('SCRATCH_DIR', '.')\n",
    "entity = os.getenv('WANDB_SEM_UNC_ENTITY', None)\n",
    "dir = f\"{scratch_dir}/{user}/uncertainty\"\n",
    "if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "project = config[\"wandb\"][\"project\"]\n",
    "if config[\"wandb\"][\"debug\"]:\n",
    "    project = f\"{project}_debug\"\n",
    "experiment_lot = config[\"wandb\"]['experiment_lot']\n",
    "notes=f'slurm_id: {slurm_jobid}, experiment_lot: {experiment_lot}'\n",
    "wandb.init(\n",
    "            entity=entity,\n",
    "            project=project,\n",
    "            dir=dir,\n",
    "            notes=notes,\n",
    "            config={**old_run.config},\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_wandb(object, file):\n",
    "    with open(f'{wandb.run.dir}/{file}', 'wb') as f:\n",
    "        pickle.dump(object, f)\n",
    "    wandb.save(f'{wandb.run.dir}/{file}')\n",
    "    print(f\"File saved and uploaded to WandB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download: requirements.txt\n",
      "File saved as: ./yw699/uncertainty/wandb/run-20241119_203456-3rp0xrrf/files/requirements.txt\n",
      "Download: wandb-metadata.json\n",
      "File saved as: ./yw699/uncertainty/wandb/run-20241119_203456-3rp0xrrf/files/wandb-metadata.json\n",
      "Download: yw699/uncertainty/wandb/run-20241119_152837-k0fk4l54/files/experiment_details.pkl\n",
      "File saved as: ./yw699/uncertainty/wandb/run-20241119_203456-3rp0xrrf/files/experiment_details.pkl\n",
      "Download: yw699/uncertainty/wandb/run-20241119_152837-k0fk4l54/files/train_generations.pkl\n",
      "File saved as: ./yw699/uncertainty/wandb/run-20241119_203456-3rp0xrrf/files/train_generations.pkl\n",
      "Download: yw699/uncertainty/wandb/run-20241119_152837-k0fk4l54/files/uncertainty_measures.pkl\n",
      "File saved as: ./yw699/uncertainty/wandb/run-20241119_203456-3rp0xrrf/files/uncertainty_measures.pkl\n",
      "Download: yw699/uncertainty/wandb/run-20241119_152837-k0fk4l54/files/validation_generations.pkl\n",
      "File saved as: ./yw699/uncertainty/wandb/run-20241119_203456-3rp0xrrf/files/validation_generations.pkl\n",
      "Deleted empty directory: ./yw699/uncertainty/wandb/run-20241119_203456-3rp0xrrf/files/yw699/uncertainty/wandb/run-20241119_152837-k0fk4l54/files\n",
      "Deleted empty directory: ./yw699/uncertainty/wandb/run-20241119_203456-3rp0xrrf/files/yw699/uncertainty/wandb/run-20241119_152837-k0fk4l54\n"
     ]
    }
   ],
   "source": [
    "save_dir = wandb.run.dir\n",
    "for file in old_run.files():\n",
    "    print(f\"Download: {file.name}\")\n",
    "    \n",
    "    file.download(root=save_dir, replace=True)\n",
    "    \n",
    "    file_name = file.name.split(\"/\")[-1]\n",
    "    \n",
    "    original_path = os.path.join(save_dir, file.name)  \n",
    "    new_path = os.path.join(save_dir, file_name) \n",
    "    \n",
    "    os.rename(original_path, new_path)  \n",
    "    print(f\"File saved as: {new_path}\")\n",
    "\n",
    "    wandb.save(new_path)\n",
    "for root, dirs, _ in os.walk(save_dir, topdown=False):\n",
    "        for dir_name in dirs:\n",
    "            dir_path = os.path.join(root, dir_name)\n",
    "            if not os.listdir(dir_path):  \n",
    "                os.rmdir(dir_path)\n",
    "                print(f\"Deleted empty directory: {dir_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uncertainty_measures': {'p_false': [1.2268030792474747, 1.2279730141162872, 1.2496417760849], 'p_false_fixed': [0.20292227201728397, 0.2038542557579629, 0.22092018188747176]}}\n",
      "{'5728eb1a3acd2414000e01c6': {'question': 'Why is the need for acceptance of punishment needed?', 'context': \"Some civil disobedients feel it is incumbent upon them to accept punishment because of their belief in the validity of the social contract, which is held to bind all to obey the laws that a government meeting certain standards of legitimacy has established, or else suffer the penalties set out in the law. Other civil disobedients who favor the existence of government still don't believe in the legitimacy of their particular government, or don't believe in the legitimacy of a particular law it has enacted. And still other civil disobedients, being anarchists, don't believe in the legitimacy of any government, and therefore see no need to accept punishment for a violation of criminal law that does not infringe the rights of others.\", 'most_likely_answer': {'response': 'social contract', 'token_log_likelihoods': [0.0, 0.0], 'accuracy': 1.0}, 'reference': {'answers': {'answer_start': [107, 87, 76, 93, 87], 'text': ['validity of the social contract', 'their belief in the validity of the social contract', 'because of their belief in the validity of the social contract', 'belief in the validity of the social contract', 'their belief in the validity of the social contract']}, 'id': '5728eb1a3acd2414000e01c6'}, 'responses': [('social contract', [0.0, 0.0], 1.0), ('social contract', [0.0, 0.0], 1.0)]}, '572f6c85947a6a140053c942': {'question': \"What is Europe's largest inland port?\", 'context': \"Until the early 1980s, industry was a major source of water pollution. Although many plants and factories can be found along the Rhine up into Switzerland, it is along the Lower Rhine that the bulk of them are concentrated, as the river passes the major cities of Cologne, Düsseldorf and Duisburg. Duisburg is the home of Europe's largest inland port and functions as a hub to the sea ports of Rotterdam, Antwerp and Amsterdam. The Ruhr, which joins the Rhine in Duisburg, is nowadays a clean river, thanks to a combination of stricter environmental controls, a transition from heavy industry to light industry and cleanup measures, such as the reforestation of Slag and brownfields. The Ruhr currently provides the region with drinking water. It contributes 70 m3/s (2,500 cu ft/s) to the Rhine. Other rivers in the Ruhr Area, above all, the Emscher, still carry a considerable degree of pollution.\", 'most_likely_answer': {'response': 'Duisburg', 'token_log_likelihoods': [0.0, 0.0, 0.0], 'accuracy': 1.0}, 'reference': {'answers': {'answer_start': [298, 298, 298], 'text': ['Duisburg', 'Duisburg', 'Duisburg']}, 'id': '572f6c85947a6a140053c942'}, 'responses': [('Duisburg', [0.0, 0.0, 0.0], 1.0), ('Duisburg', [0.0, 0.0, 0.0], 1.0)]}, '57268f2bf1498d1400e8e3c7': {'question': 'What treaty took the place of constitutional treaty? ', 'context': 'Following the Nice Treaty, there was an attempt to reform the constitutional law of the European Union and make it more transparent; this would have also produced a single constitutional document. However, as a result of the referendum in France and the referendum in the Netherlands, the 2004 Treaty establishing a Constitution for Europe never came into force. Instead, the Lisbon Treaty was enacted. Its substance was very similar to the proposed constitutional treaty, but it was formally an amending treaty, and – though it significantly altered the existing treaties – it did not completely replace them.', 'most_likely_answer': {'response': 'Lisbon Treaty', 'token_log_likelihoods': [0.0, 0.0, 0.0, 0.0], 'accuracy': 1.0}, 'reference': {'answers': {'answer_start': [372, 372, 372, 372], 'text': ['the Lisbon Treaty', 'the Lisbon Treaty', 'the Lisbon Treaty', 'the Lisbon Treaty']}, 'id': '57268f2bf1498d1400e8e3c7'}, 'responses': [('Lisbon Treaty', [0.0, 0.0, 0.0, 0.0], 1.0), ('Lisbon Treaty', [0.0, 0.0, 0.0, 0.0], 1.0)]}}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "base_path = './yw699/uncertainty/wandb/run-20241119_154636-5b5le9ev/files'\n",
    "file_name = \"uncertainty_measures.pkl\"\n",
    "\n",
    "with open(f'{base_path}/{file_name}', 'rb') as f:\n",
    "    result_dict = pickle.load(f)\n",
    "\n",
    "print(result_dict)\n",
    "\n",
    "\n",
    "\n",
    "file_name = \"validation_generations.pkl\"\n",
    "with open(f'{base_path}/{file_name}', 'rb') as f:\n",
    "    validation_generations = pickle.load(f)\n",
    "\n",
    "\n",
    "print(validation_generations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "result_dict['semantic_ids'] = []\n",
    "entropies = defaultdict(list)\n",
    "validation_embeddings, validation_is_true, validation_answerable = [], [], []\n",
    "p_trues = []\n",
    "count = 0  \n",
    "\n",
    "def is_answerable(generation):\n",
    "    return len(generation['reference']['answers']['text']) > 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_all_generations = False\n",
    "use_num_generations =2\n",
    "num_eval_samples = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## compute_predictive_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 20:35:52 INFO     validation_is_true: 1.000000\n",
      "2024-11-19 20:35:52 INFO     validation_is_true: 1.000000\n",
      "2024-11-19 20:35:52 INFO     validation_is_true: 1.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': 'social contract', 'token_log_likelihoods': [0.0, 0.0], 'accuracy': 1.0}\n",
      "{'response': 'Duisburg', 'token_log_likelihoods': [0.0, 0.0, 0.0], 'accuracy': 1.0}\n",
      "{'response': 'Lisbon Treaty', 'token_log_likelihoods': [0.0, 0.0, 0.0, 0.0], 'accuracy': 1.0}\n"
     ]
    }
   ],
   "source": [
    "for idx, tid in enumerate(validation_generations):\n",
    "\n",
    "        example = validation_generations[tid]\n",
    "        question = example['question']\n",
    "        context = example['context']\n",
    "        full_responses = example[\"responses\"]\n",
    "        most_likely_answer = example['most_likely_answer']\n",
    "        print(most_likely_answer)\n",
    "        if not use_all_generations:\n",
    "            if use_num_generations == -1:\n",
    "                raise ValueError\n",
    "            responses = [fr[0] for fr in full_responses[:use_num_generations]]\n",
    "        else:\n",
    "            responses = [fr[0] for fr in full_responses]\n",
    "\n",
    "        validation_is_true.append(most_likely_answer['accuracy'])\n",
    "        validation_answerable.append(is_answerable(example))\n",
    "        #validation_embeddings.append(most_likely_answer['embedding'])\n",
    "        logging.info('validation_is_true: %f', validation_is_true[-1])\n",
    "        count += 1\n",
    "        if count >= num_eval_samples:\n",
    "            logging.info('Breaking out of main loop.')\n",
    "            break\n",
    "        if not use_all_generations:\n",
    "            log_liks = [r[1] for r in full_responses[:use_num_generations]]\n",
    "        else:\n",
    "            log_liks = [r[1] for r in full_responses]\n",
    "        for i in log_liks:\n",
    "            assert i\n",
    "        \n",
    "        entropies['context_entails_response'].append(context_entails_response(context, responses, entailment_model))\n",
    "\n",
    "        if args.condition_on_question and args.entailment_model == 'deberta':\n",
    "                responses = [f'{question} {r}' for r in responses]\n",
    "        semantic_ids = get_semantic_ids(responses, model=entailment_model,strict_entailment=args.strict_entailment, example=example)\n",
    "        result_dict['semantic_ids'].append(semantic_ids)\n",
    "        entropies['cluster_assignment_entropy'].append(cluster_assignment_entropy(semantic_ids))\n",
    "\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.compute_predictive_entropy:\n",
    "            # Token log likelihoods. Shape = (n_sample, n_tokens)\n",
    "            if not args.use_all_generations:\n",
    "                log_liks = [r[1] for r in full_responses[:args.use_num_generations]]\n",
    "            else:\n",
    "                log_liks = [r[1] for r in full_responses]\n",
    "\n",
    "            for i in log_liks:\n",
    "                assert i\n",
    "\n",
    "            if args.compute_context_entails_response:\n",
    "                # Compute context entails answer baseline.\n",
    "                entropies['context_entails_response'].append(context_entails_response(\n",
    "                    context, responses, entailment_model))\n",
    "\n",
    "            if args.condition_on_question and args.entailment_model == 'deberta':\n",
    "                responses = [f'{question} {r}' for r in responses]\n",
    "\n",
    "            # Compute semantic ids.\n",
    "            semantic_ids = get_semantic_ids(\n",
    "                responses, model=entailment_model,\n",
    "                strict_entailment=args.strict_entailment, example=example)\n",
    "\n",
    "            result_dict['semantic_ids'].append(semantic_ids)\n",
    "\n",
    "            # Compute entropy from frequencies of cluster assignments.\n",
    "            entropies['cluster_assignment_entropy'].append(cluster_assignment_entropy(semantic_ids))\n",
    "\n",
    "            # Length normalization of generation probabilities.\n",
    "            log_liks_agg = [np.mean(log_lik) for log_lik in log_liks]\n",
    "\n",
    "            # Compute naive entropy.\n",
    "            entropies['regular_entropy'].append(predictive_entropy(log_liks_agg))\n",
    "\n",
    "            # Compute semantic entropy.\n",
    "            log_likelihood_per_semantic_id = logsumexp_by_id(semantic_ids, log_liks_agg, agg='sum_normalized')\n",
    "            pe = predictive_entropy_rao(log_likelihood_per_semantic_id)\n",
    "            entropies['semantic_entropy'].append(pe)\n",
    "\n",
    "            # pylint: disable=invalid-name\n",
    "            log_str = 'semantic_ids: %s, avg_token_log_likelihoods: %s, entropies: %s'\n",
    "            entropies_fmt = ', '.join([f'{i}:{j[-1]:.2f}' for i, j in entropies.items()])\n",
    "            # pylint: enable=invalid-name\n",
    "            logging.info(80*'#')\n",
    "            logging.info('NEW ITEM %d at id=`%s`.', idx, tid)\n",
    "            logging.info('Context:')\n",
    "            logging.info(example['context'])\n",
    "            logging.info('Question:')\n",
    "            logging.info(question)\n",
    "            logging.info('True Answers:')\n",
    "            logging.info(example['reference'])\n",
    "            logging.info('Low Temperature Generation:')\n",
    "            logging.info(most_likely_answer['response'])\n",
    "            logging.info('Low Temperature Generation Accuracy:')\n",
    "            logging.info(most_likely_answer['accuracy'])\n",
    "            logging.info('High Temp Generation:')\n",
    "            logging.info([r[0] for r in full_responses])\n",
    "            logging.info('High Temp Generation:')\n",
    "            logging.info(log_str, semantic_ids, log_liks_agg, entropies_fmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semantic_uncertainty",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
